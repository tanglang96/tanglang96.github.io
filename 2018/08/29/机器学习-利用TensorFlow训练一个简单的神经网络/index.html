<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>[机器学习]利用TensorFlow训练一个简单的神经网络 | Math &amp; Code</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="利用TensorFlow训练一个简单的神经网络我们在这里利用TensorFlow的Eager Execution 来构建模型，这样不用像以前一样创建Graph和Session了，可以使神经网络的训练更加方便快捷，下面以Iris数据集为例来训练一个神经网络，代码来自谷歌的教程。1234567891011#先导入相关的库from __future__ import absolute_import,di">
<meta name="keywords" content="machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="[机器学习]利用TensorFlow训练一个简单的神经网络">
<meta property="og:url" content="http://yoursite.com/2018/08/29/机器学习-利用TensorFlow训练一个简单的神经网络/index.html">
<meta property="og:site_name" content="Math &amp; Code">
<meta property="og:description" content="利用TensorFlow训练一个简单的神经网络我们在这里利用TensorFlow的Eager Execution 来构建模型，这样不用像以前一样创建Graph和Session了，可以使神经网络的训练更加方便快捷，下面以Iris数据集为例来训练一个神经网络，代码来自谷歌的教程。1234567891011#先导入相关的库from __future__ import absolute_import,di">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://img-blog.csdn.net/20180706222128445?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:updated_time" content="2018-08-29T13:19:30.047Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[机器学习]利用TensorFlow训练一个简单的神经网络">
<meta name="twitter:description" content="利用TensorFlow训练一个简单的神经网络我们在这里利用TensorFlow的Eager Execution 来构建模型，这样不用像以前一样创建Graph和Session了，可以使神经网络的训练更加方便快捷，下面以Iris数据集为例来训练一个神经网络，代码来自谷歌的教程。1234567891011#先导入相关的库from __future__ import absolute_import,di">
<meta name="twitter:image" content="https://img-blog.csdn.net/20180706222128445?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
  
    <link rel="alternate" href="/atom.xml" title="Math &amp; Code" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Math &amp; Code</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习-利用TensorFlow训练一个简单的神经网络" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/29/机器学习-利用TensorFlow训练一个简单的神经网络/" class="article-date">
  <time datetime="2018-08-29T10:43:05.000Z" itemprop="datePublished">2018-08-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      [机器学习]利用TensorFlow训练一个简单的神经网络
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="利用TensorFlow训练一个简单的神经网络"><a href="#利用TensorFlow训练一个简单的神经网络" class="headerlink" title="利用TensorFlow训练一个简单的神经网络"></a>利用TensorFlow训练一个简单的神经网络</h1><p>我们在这里利用TensorFlow的Eager Execution 来构建模型，这样不用像以前一样创建Graph和Session了，可以使神经网络的训练更加方便快捷，下面以Iris数据集为例来训练一个神经网络，代码来自谷歌的教程。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先导入相关的库</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import,division,print_function</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.contrib.eager <span class="keyword">as</span> tfe</span><br><span class="line"></span><br><span class="line">tf.enable_eager_execution()	<span class="comment">#采用eager_execution</span></span><br><span class="line"><span class="comment">#查看版本信息并检查采用eager_execution是否打开</span></span><br><span class="line">print(<span class="string">'TensorFlow Version:&#123;&#125;'</span>.format(tf.VERSION))</span><br><span class="line">print(<span class="string">'Eager execution:&#123;&#125;'</span>.format(tf.executing_eagerly()))</span><br></pre></td></tr></table></figure></p>
<p>TensorFlow Version:1.8.0<br>Eager execution:True<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#获取数据集并显示在本地的保存位置</span><br><span class="line">train_dataset_url=&apos;http://download.tensorflow.org/data/iris_training.csv&apos;</span><br><span class="line">train_dataset_fp=tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),origin=train_dataset_url)</span><br><span class="line">print(&apos;Local copy of the dataset file:&#123;&#125;&apos;.format(train_dataset_fp))</span><br></pre></td></tr></table></figure></p>
<p>Downloading data from <a href="http://download.tensorflow.org/data/iris_training.csv" target="_blank" rel="noopener">http://download.tensorflow.org/data/iris_training.csv</a><br>8192/2194 [================================================================================================================] - 0s 0us/step<br>Local copy of the dataset file:C:\Users\Frank.keras\datasets\iris_training.csv<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#对表格文件中的每一行进行解析，每行有5个元素，前面4个是特征，最后一个是标记</span><br><span class="line">def parse_csv(line):</span><br><span class="line">    example_defaults=[[0.],[0.],[0.],[0.],[0]]</span><br><span class="line">    parsed_line=tf.decode_csv(line,example_defaults)</span><br><span class="line">    features=tf.reshape(parsed_line[:-1],shape=(4,))</span><br><span class="line">    label=tf.reshape(parsed_line[-1],shape=())</span><br><span class="line">    return features,label</span><br><span class="line">	</span><br><span class="line">train_dataset=tf.data.TextLineDataset(train_dataset_fp)	#读取csv转换为dataset</span><br><span class="line">train_dataset=train_dataset.skip(1)	#跳过标题行</span><br><span class="line">train_dataset=train_dataset.map(parse_csv)	#对每一行都进行映射</span><br><span class="line">train_dataset=train_dataset.shuffle(buffer_size=1000)	#随机打乱</span><br><span class="line">train_dataset=train_dataset.batch(32)	#分批</span><br><span class="line"></span><br><span class="line">#打印一组训练数据</span><br><span class="line">features,label=iter(train_dataset).next()</span><br><span class="line">print(&apos;example features:&apos;,features[0])</span><br><span class="line">print(&apos;example label:&apos;,label[0])</span><br></pre></td></tr></table></figure></p>
<p>example features: tf.Tensor([6.8 3.  5.5 2.1], shape=(4,), dtype=float32)<br>example label: tf.Tensor(2, shape=(), dtype=int32)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#建立神经网络模型，两个隐藏层</span><br><span class="line">model=tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(10,activation=&apos;relu&apos;,input_shape=(4,)),</span><br><span class="line">    tf.keras.layers.Dense(10,activation=&apos;relu&apos;),</span><br><span class="line">    tf.keras.layers.Dense(3)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">#定义损失函数为softmax后的cross_entropy，返回一个损失函数的对象</span><br><span class="line">def loss(model,x,y):</span><br><span class="line">    y_=model(x)</span><br><span class="line">    return tf.losses.sparse_softmax_cross_entropy(labels=y,logits=y_)</span><br><span class="line"></span><br><span class="line">#返回一个梯度对象</span><br><span class="line">def grad(model,inputs,targets):</span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        loss_value=loss(model,inputs,targets)</span><br><span class="line">    return tape.gradient(loss_value,model.variables)	#返回梯度对象，传入损失函数和优化对象作为构造函数的参数</span><br><span class="line"></span><br><span class="line">optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)</span><br><span class="line"></span><br><span class="line">train_loss_results=[]</span><br><span class="line">train_accuracy_results=[]</span><br><span class="line">num_epochs=201</span><br><span class="line"></span><br><span class="line">#优化过程迭代201次</span><br><span class="line">for epoch in range(num_epochs):</span><br><span class="line">    epoch_loss_avg=tfe.metrics.Mean()	#交叉熵的平均误差对象</span><br><span class="line">    epoch_accuracy=tfe.metrics.Accuracy()	#准确率对象</span><br><span class="line">    </span><br><span class="line">    for x,y in train_dataset:</span><br><span class="line">        grads=grad(model,x,y)</span><br><span class="line">        optimizer.apply_gradients(zip(grads, model.variables),	#将梯度对应的模型变量分组</span><br><span class="line">                              global_step=tf.train.get_or_create_global_step())</span><br><span class="line">        epoch_loss_avg(loss(model,x,y))</span><br><span class="line">        epoch_accuracy(tf.argmax(model(x),axis=1,output_type=tf.int32),y)</span><br><span class="line">    train_loss_results.append(epoch_loss_avg.result())</span><br><span class="line">    train_accuracy_results.append(epoch_accuracy.result())</span><br><span class="line">    if epoch % 50 == 0:</span><br><span class="line">        print(&quot;Epoch &#123;:03d&#125;: Loss: &#123;:.3f&#125;, Accuracy: &#123;:.3%&#125;&quot;.format(epoch,epoch_loss_avg.result(),epoch_accuracy.result()</span><br></pre></td></tr></table></figure></p>
<p>Epoch 000: Loss: 1.217, Accuracy: 30.833%<br>Epoch 050: Loss: 0.524, Accuracy: 93.333%<br>Epoch 100: Loss: 0.261, Accuracy: 96.667%<br>Epoch 150: Loss: 0.169, Accuracy: 97.500%<br>Epoch 200: Loss: 0.133, Accuracy: 97.500%<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#训练过程损失函数和准确率的可视化																</span><br><span class="line">fig,axes=plt.subplots(2,sharex=True,figsize=(12,8))</span><br><span class="line">fig.suptitle(&apos;Training Metrics&apos;)</span><br><span class="line">axes[0].set_ylabel(&quot;Loss&quot;, fontsize=14)</span><br><span class="line">axes[0].plot(train_loss_results)</span><br><span class="line"></span><br><span class="line">axes[1].set_ylabel(&quot;Accuracy&quot;, fontsize=14)</span><br><span class="line">axes[1].set_xlabel(&quot;Epoch&quot;, fontsize=14)</span><br><span class="line">axes[1].plot(train_accuracy_results)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p>
<p><img src="https://img-blog.csdn.net/20180706222128445?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#在测试集上测试模型表现</span><br><span class="line">test_url = &quot;http://download.tensorflow.org/data/iris_test.csv&quot;</span><br><span class="line"></span><br><span class="line">test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),</span><br><span class="line">                                  origin=test_url)</span><br><span class="line"></span><br><span class="line">test_dataset = tf.data.TextLineDataset(test_fp)</span><br><span class="line">test_dataset = test_dataset.skip(1)</span><br><span class="line">test_dataset = test_dataset.map(parse_csv)</span><br><span class="line">test_dataset = test_dataset.shuffle(1000)</span><br><span class="line">test_dataset = test_dataset.batch(32)</span><br><span class="line"></span><br><span class="line">test_accuracy = tfe.metrics.Accuracy()</span><br><span class="line"></span><br><span class="line">for (x, y) in test_dataset:</span><br><span class="line">  prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)</span><br><span class="line">  test_accuracy(prediction, y)</span><br><span class="line"></span><br><span class="line">print(&quot;Test set accuracy: &#123;:.3%&#125;&quot;.format(test_accuracy.result()))</span><br></pre></td></tr></table></figure></p>
<p>Test set accuracy: 100.000%<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#使用模型来进行预测</span><br><span class="line">class_ids = [&quot;Iris setosa&quot;, &quot;Iris versicolor&quot;, &quot;Iris virginica&quot;]</span><br><span class="line">predict_dataset = tf.convert_to_tensor([</span><br><span class="line">    [5.1, 3.3, 1.7, 0.5,],</span><br><span class="line">    [5.9, 3.0, 4.2, 1.5,],</span><br><span class="line">    [6.9, 3.1, 5.4, 2.1]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">predictions = model(predict_dataset)</span><br><span class="line"></span><br><span class="line">for i, logits in enumerate(predictions):</span><br><span class="line">  class_idx = tf.argmax(logits).numpy()</span><br><span class="line">  name = class_ids[class_idx]</span><br><span class="line">  print(&quot;Example &#123;&#125; prediction: &#123;&#125;&quot;.format(i, name))</span><br></pre></td></tr></table></figure></p>
<p>Example 0 prediction: Iris setosa<br>Example 1 prediction: Iris versicolor<br>Example 2 prediction: Iris virginica</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/29/机器学习-利用TensorFlow训练一个简单的神经网络/" data-id="cjlf7obxa0010i4ezs7f7mxre" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/08/29/机器学习-在极客云上进行深度学习/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          [机器学习]在极客云上进行深度学习
        
      </div>
    </a>
  
  
    <a href="/2018/08/29/机器学习-机器学习中的数值计算-1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">[机器学习]机器学习中的数值计算(1)</div>
    </a>
  
</nav>

  
</article>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cpp/">Cpp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/optimization/">optimization</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Cpp/" style="font-size: 15px;">Cpp</a> <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a> <a href="/tags/optimization/" style="font-size: 20px;">optimization</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/08/29/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/08/29/Cpp-谈一谈const关键字/">[Cpp]谈一谈const关键字</a>
          </li>
        
          <li>
            <a href="/2018/08/29/最优化-线性规划概述/">[最优化]线性规划概述</a>
          </li>
        
          <li>
            <a href="/2018/08/29/最优化-求解线性规划问题的单纯形算法/">[最优化]求解线性规划问题的单纯形算法</a>
          </li>
        
          <li>
            <a href="/2018/08/29/Cpp-Cpp函数中的参数传递/">[Cpp]Cpp函数中的参数传递</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Tang Lang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>
</html>