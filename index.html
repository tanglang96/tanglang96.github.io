<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Math &amp; Code</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="the best or nothing">
<meta name="keywords" content="Algorithm">
<meta property="og:type" content="website">
<meta property="og:title" content="Math &amp; Code">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Math &amp; Code">
<meta property="og:description" content="the best or nothing">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Math &amp; Code">
<meta name="twitter:description" content="the best or nothing">
  
    <link rel="alternate" href="/atom.xml" title="Math &amp; Code" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Math &amp; Code</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">---By Frank,the best or nothing</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-最优化-凸集的定义与常见凸集" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/31/最优化-凸集的定义与常见凸集/" class="article-date">
  <time datetime="2018-08-31T10:41:26.000Z" itemprop="datePublished">2018-08-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/31/最优化-凸集的定义与常见凸集/">[最优化]凸集的定义与常见凸集</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="凸集的定义与常见凸集"><a href="#凸集的定义与常见凸集" class="headerlink" title="凸集的定义与常见凸集"></a>凸集的定义与常见凸集</h1><p>通常认为，如果某个实际问题可以表述为凸优化问题，那么事实上已经解决了这个问题，然而凸优化问题的识别还比较困难，本文将先介绍凸集的定义与常见凸集。</p>
<h2 id="仿射集"><a href="#仿射集" class="headerlink" title="仿射集"></a>仿射集</h2><p>如果集合 <script type="math/tex">C\subseteq R^{n}</script> 是仿射的，等价于：对于任意的 <script type="math/tex">x_{1},x_{2}\in C</script> 及 <script type="math/tex">\theta \in R</script> 有 <script type="math/tex">\theta x_{1}+(1-\theta)x_{2}\in C</script> ，即 <script type="math/tex">C</script> 包含了 <script type="math/tex">C</script> 中任意两点的系数之和为1的线性组合。</p>
<p>将其扩展到多个点的情况：如果 <script type="math/tex">\theta_{1}+\theta_{2}+...+\theta_{k}=1</script> ，我们则称具有 <script type="math/tex">\theta_{1}x_{1}+\theta_{2}x_{2}+...+\theta_{k}x_{k}</script> 形式的点为 <script type="math/tex">x_{1},x_{2},...,x_{k}</script> 的仿射组合。例如线性方程组的解集 <script type="math/tex">C=\{x|Ax=b\}</script>是一个仿射集。</p>
<p>称由集合 <script type="math/tex">C\subseteq R^{n}</script> 中点的所有仿射组合所组成的集合为 <script type="math/tex">C</script> 的仿射包：</p>
<script type="math/tex; mode=display">
\mathrm{aff}\ C=\{\theta_{1}x_{1}+...+\theta_{k}x_{k}|x_{1},...,x_{k}\in C,\theta_{1}+\theta_{2}+...+\theta_{k}=1\}</script><p>仿射包是包含 <script type="math/tex">C</script> 的最小的仿射集合，即如果集合 <script type="math/tex">S</script> 满足 <script type="math/tex">C\subseteq S</script>，则 <script type="math/tex">\mathrm{aff}\ C\subseteq S</script> ，同时将集合 <script type="math/tex">C</script> 的仿射维数定义为其仿射包的维数。例如 <script type="math/tex">R^{2}</script> 上的单位圆环的维数为1，但其仿射维数为2，因为其仿射包为全空间 <script type="math/tex">R^{2}</script></p>
<h2 id="凸集"><a href="#凸集" class="headerlink" title="凸集"></a>凸集</h2><p>如果集合 <script type="math/tex">C</script> 为凸集，那么对于任意的 <script type="math/tex">x_{1},x_{2}\in C</script> 与<script type="math/tex">0\le \theta\le 1</script>都有 <script type="math/tex">\theta x_{1}+(1-\theta)x_{2}\in C</script>，与仿射集的区别在于仿射集并没有 <script type="math/tex">\theta\ge0</script> 的要求，例如一条线段是凸集，而一条直线是仿射集。</p>
<p>扩展到多维的情况，如果有 <script type="math/tex">\theta_{1}+\theta_{2}+...+\theta_{k}=1,\theta_{i}\ge0</script> ，则称具有 <script type="math/tex">\theta_{1}x_{1}+\theta_{2}x_{2}+...+\theta_{k}x_{k}</script> 形式的点为 <script type="math/tex">x_{1},x_{2},...,x_{k}</script> 的凸组合。</p>
<p>称由集合 <script type="math/tex">C\subseteq R^{n}</script> 中点的所有凸组合所组成的集合为 <script type="math/tex">C</script> 的凸包：</p>
<script type="math/tex; mode=display">
\mathrm{conv}\ C=\{\theta_{1}x_{1}+...+\theta_{k}x_{k}|x_{1},...,x_{k}\in C,\theta_{1}+...+\theta_{k}=1,\theta_{i}\ge0\}</script><p>与仿射包同样，凸包也是包含 <script type="math/tex">C</script> 的最小的凸集，在一般情况下，设 <script type="math/tex">C\in R^{n}</script> 是凸集，<script type="math/tex">x</script> 是随机变量，并且 <script type="math/tex">x\in C</script> 的概率为1，那么 <script type="math/tex">E\ x\in C</script></p>
<h2 id="一些重要的凸集"><a href="#一些重要的凸集" class="headerlink" title="一些重要的凸集"></a>一些重要的凸集</h2><p>识别出凸集对于识别凸优化问题较为重要，这里将介绍一些比较重要的凸集。</p>
<p>任意的仿射集和子空间都是凸集，一些比较简单的例如空集 <script type="math/tex">\emptyset</script> ，单点集<script type="math/tex">\{x_{0}\}</script>，全空间 <script type="math/tex">R^{n}</script> ，直线/射线/线段都是凸的。</p>
<p>还有一些比较重要的凸集如下：</p>
<ol>
<li>超平面 <script type="math/tex">\{x|a^{T}x=b \}</script>和半空间 <script type="math/tex">\{x|a^{T}x\le b\}</script></li>
<li>Euclid球 <script type="math/tex">B(x_{c},r)=\{x|\ ||x-x_{c}||_{2}\le r\}</script></li>
<li>椭球 <script type="math/tex">\xi=\{x|(x-x_{c})^{T}P^{-1}(x-x_{c})\le1\}</script></li>
<li>范数球 <script type="math/tex">\{x|\ ||x-x_{c}||\le r\}</script>，其中 <script type="math/tex">||\cdot||</script> 是 <script type="math/tex">R^{n}</script> 中的范数</li>
<li>范数锥 <script type="math/tex">C=\{(x,t)|\ ||x||\le t\}\subseteq R^{n+1}</script></li>
<li>多面体 <script type="math/tex">P=\{x|a_{j}^{T}\le b_{j},j=1,...,m,c_{j}^{T}x=d_{j},j=1,...,p\}</script>，即为有限个半空间和超平面的交集，单纯形也为凸集，是一种特殊的多面体</li>
<li>半正定锥 <script type="math/tex">S_{+}^{n}=\{X\in R^{n*n}|X=X^{T},X\succeq0\}</script>，即为半正定对称矩阵的集合</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/31/最优化-凸集的定义与常见凸集/" data-id="cjlote7m0000yx4ez421n0a26" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/optimization/">optimization</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-SVM的推导-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/24/机器学习-SVM的推导-3/" class="article-date">
  <time datetime="2018-08-24T02:50:36.000Z" itemprop="datePublished">2018-08-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/24/机器学习-SVM的推导-3/">[机器学习]SVM的推导(3)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="软间隔SVM的推导"><a href="#软间隔SVM的推导" class="headerlink" title="软间隔SVM的推导"></a>软间隔SVM的推导</h1><p>前文介绍了硬间隔SVM的相关推导，本文将继续介绍软间隔SVM的数学推导，即在样本不是线性可分的情况下，允许一部分样本错误分类的SVM。软间隔SVM允许一部分样本不满足约束：$y_{i}(w\cdot x_{i})\ge 0$</p>
<p>可以将优化目标写为：</p>
<script type="math/tex; mode=display">
min_{w,b}\quad \frac{1}{2}||w||^{2}+C\sum_{i=1}^{m}loss(y_{i}(w\cdot x_{i}+b)-1)</script><p>其中 $C$ 是一个常数，用来衡量允许的不满足约束的程度，其中的 $loss()$ 函数可以使用 $hinge()$ 函数，即 $loss_{hinge}(z)=max(0,1-z)$</p>
<p>那么可以将优化目标写为：</p>
<script type="math/tex; mode=display">
min_{w,b}\quad \frac{1}{2}||w||^{2}+C\sum_{i=1}^{m}max(0,1-y_{i}(w\cdot x_{i}+b))</script><p>引入“松弛变量” $\xi_{i}\ge 0$ ，可以将上式改写为</p>
<script type="math/tex; mode=display">
\begin{align*}
min_{w,b,\xi_{i}}\quad& \frac{1}{2}||w||^{2}+C\sum_{i=1}^{m}\xi_{i}\\
s.t.\quad& y_{i}(w\cdot x_{i}+b)\ge1-\xi_{i}\\
&\xi_{i}\ge0,i=1,2,...,m
\end{align*}</script><p>与硬间隔SVM类似，上述的问题也是个二次规划的问题，可以先用拉格朗日对偶性将其转换为对应的对偶问题，再用SMO算法求解。上面问题对应的拉格朗日函数为：</p>
<script type="math/tex; mode=display">
L(w,b,\alpha,\xi,\mu)=\frac{1}{2}||w||^{2}+C\sum_{i=1}^{m}\xi_{i}\\+\sum_{i=1}^{m}\alpha_{i}(1-\xi_{i}-y_{i}(w\cdot x_{i}+b))-\sum_{i=1}^{m}\mu_{i}\xi_{i}</script><p>令 $L$ 对 $w,b,\alpha$ 的偏导为 $0$ 可以得到</p>
<script type="math/tex; mode=display">
w=\sum_{i=1}^{m}\alpha_{i}y_{i}x_{i}\\
0=\sum_{i=1}^{m}\alpha_{i}y_{i}\\
C=\alpha_{i}+\mu_{i}</script><p>代入 $L(w,b,\alpha,\xi,\mu)$ 即可以将原问题化成对偶问题：</p>
<script type="math/tex; mode=display">
\begin{align*}
min_ \alpha\quad &\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}\cdot x_{j}-\sum_{i=1}^{m}\alpha_{i}\\
s.t.\quad &\sum_{i=1}^{m}\alpha_{i}y_{i}=0\\
&C\ge \alpha_{i}\ge 0\\
&i=1,2,...,m
\end{align*}</script><p>可以看出其与硬间隔SVM唯一的区别在于 $\alpha_{i}\ge 0$变成了 $C\ge \alpha_{i}\ge 0$，同样可以用上文中提到的SMO算法很方便的求解，唯一的区别在于剪辑的时候需要考虑两个方向。</p>
<p>后面还会介绍SVM的核技巧以及常用核，To be continue…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/24/机器学习-SVM的推导-3/" data-id="cjlote7m50013x4ezmuniw1d7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-SVM的推导-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/18/机器学习-SVM的推导-2/" class="article-date">
  <time datetime="2018-08-18T08:54:25.000Z" itemprop="datePublished">2018-08-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/18/机器学习-SVM的推导-2/">[机器学习]SVM的推导(2)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="硬间隔SVM的SMO序列优化算法"><a href="#硬间隔SVM的SMO序列优化算法" class="headerlink" title="硬间隔SVM的SMO序列优化算法"></a>硬间隔SVM的SMO序列优化算法</h1><p>上一篇文章(1)我们讨论了硬间隔SVM的推导及其对偶形式，其对偶问题可以化简成以下形式：</p>
<script type="math/tex; mode=display">\begin{align*}
min_ \alpha\quad &\frac{1}{2}\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}\cdot x_{j}-\sum_{i=1}^{N}\alpha_{i}\\
s.t.\quad &\sum_{i=1}^{N}\alpha_{i}y_{i}=0\\
&\alpha_{i}\ge 0\\
&i=1,2,...,N
\end{align*}</script><p>该问题可以看作是一个以<script type="math/tex">\alpha</script>为优化变量的二阶规划问题，二阶规划问题有很多成熟的解法，针对SVM的优化有一种最为高效的SMO序列优化算法。</p>
<h1 id="SMO序列优化算法"><a href="#SMO序列优化算法" class="headerlink" title="SMO序列优化算法"></a>SMO序列优化算法</h1><p>SMO序列优化算法先将<script type="math/tex">\alpha</script>的所有变量进行初始化，比如令<script type="math/tex">\alpha_{1},\alpha_{2},...,\alpha_{N}=0，</script>再将<script type="math/tex">\alpha</script>的其中两个分量看作变量，比如<script type="math/tex">\alpha_{1},\alpha_{2}</script>（在选取两个分量<script type="math/tex">\alpha_{i},\alpha_{j}</script>的时候，通常先取违反上文中KKT条件最严重的为<script type="math/tex">\alpha_{i}</script>，然后选取离<script type="math/tex">x_{i}</script>间隔最远的<script type="math/tex">x_{j}</script>对应的<script type="math/tex">\alpha_{j}</script>为第二个变量），其余的<script type="math/tex">\alpha_{3},\alpha_{4},...,\alpha_{N}</script>固定住，则根据约束条件<script type="math/tex">\sum_{i=1}^{N}\alpha_{i}y_{i}=0</script>可以得到<script type="math/tex">\alpha_{1}=-y_{1}\sum_{i=2}^{N}\alpha_{i}y_{i}</script>。上述问题即可以化为两个变量的二次规划问题(令<script type="math/tex">K_{ij}=x_{i}\cdot x_{j}</script>)：</p>
<script type="math/tex; mode=display">\begin{align*}
min_{\alpha_{1},\alpha_{2}}\quad W(\alpha_{1},\alpha_{2})=&\frac{1}{2}K_{11}\alpha_{1}^{2}+\frac{1}{2}K_{22}\alpha_{2}^{2}+y_{1}y_{2}K_{12}\alpha_{1}\alpha_{2}\\
&-(\alpha_{1}+\alpha_{2})+y_{1}\alpha_{1}\sum_{i=3}^{N}y_{i}\alpha_{i}K_{i1}+y_{2}\alpha_{2}\sum_{i=3}^{N}y_{i}\alpha_{i}K_{i2}\\
s.t.\quad &\alpha_{1}y_{1}+\alpha_{2}y_{2}=-\sum_{i=3}^{N}y_{i}\alpha_{i}=\zeta\\
&\alpha_{1},\alpha_{2}\ge0
\end{align*}</script><p>在上述二次规划问题中，由于<script type="math/tex">\alpha_{1}y_{1}+\alpha_{2}y_{2}=\zeta</script>，那么可以得到<script type="math/tex">\alpha_{1}=(\zeta-y_{2}\alpha_{2})y_{1}</script>，将该约束条件代入<script type="math/tex">W(\alpha_{1},\alpha_{2})</script>中即可以得到单变量的二次规划问题，如果先不考虑不等式约束条件，则可以直接得到解析解，不必利用数值计算的方式求解，这样可以大大提升计算速度。</p>
<p>令<script type="math/tex">v_{i}=\sum_{j=3}^{N}\alpha_{j}y_{j}K(x_{i},x_{j})</script>，则将<script type="math/tex">\alpha_{1}=(\zeta-y_{2}\alpha_{2})y_{1}</script>代入<script type="math/tex">W(\alpha_{1},\alpha_{2})</script>可以得到：</p>
<script type="math/tex; mode=display">
W(\alpha_{2})=\frac{1}{2}K_{11}(\zeta-\alpha_{2}y_{2})^{2}+\frac{1}{2}K_{22}\alpha_{2}^{2}+y_{2}K_{12}(\zeta-\alpha_{2}y_{2})\alpha_{2}-(\zeta-\alpha_{2}y_{2})y_{1}-\alpha_{2}+v_{1}(\zeta-\alpha_{2}y_{2})+y_{2}v_{2}\alpha_{2}</script><p>直接令<script type="math/tex">\frac{\partial W}{\partial\alpha_{2}}=0</script>，那么可以得到<script type="math/tex">\alpha_{2}</script>的解析解为<script type="math/tex">\hat\alpha_{2}=\alpha_{2}+\frac{y_{2}(E_{1}-E_{2})}{\eta}</script>，其中<script type="math/tex">E_{i}=\sum_{j=1}^{N}\alpha_{j}y_{j}K_{ij}+b-y_{i}</script>，<script type="math/tex">\eta=K_{11}+K_{22}-2K_{12}</script>。此时得到的<script type="math/tex">\hat\alpha_{2}</script>还没有考虑不等式约束<script type="math/tex">\alpha_{1},\alpha_{2}\ge 0</script>，由<script type="math/tex">\alpha_{1}=(\zeta-y_{2}\alpha_{2})y_{1}\ge0</script>与<script type="math/tex">\alpha_{2}\ge0</script>可以解不等式得到<script type="math/tex">\alpha_2</script>的上界<script type="math/tex">H</script>与下界<script type="math/tex">L</script>，即经过剪辑可以得到<script type="math/tex">\alpha_{2}</script>的解析解为：</p>
<script type="math/tex; mode=display">
\alpha_{2}^{*}=
\begin{cases}
H,\quad \hat\alpha_{2}>H\\
\hat\alpha_{2},\quad L\le\hat\alpha_{2}\le H\\
L,\quad \hat\alpha_{2}<L
\end{cases}</script><p>另外根据<script type="math/tex">\alpha_{1}^{*}=(\zeta-y_{2}\alpha_{2}^{*})y_{1}</script>则可以得到<script type="math/tex">\alpha_{1}^{*}</script>，这样便完成了SMO算法的一组变量的更新。重复进行变量选择，解析求解，变量剪辑的过程，直到<script type="math/tex">\alpha</script>的所有变量都能满足文章(1)中的KKT条件为止，然后再根据文章(1)中<script type="math/tex">w</script>与<script type="math/tex">b</script>的计算公式便可以得到训练好的超平面，这样便完成了硬间隔SVM的数学推导过程，后面的文章还会继续介绍软间隔SVM的推导与核方法的应用。To be continue…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/18/机器学习-SVM的推导-2/" data-id="cjlote7m70015x4ezwlfnrj1v" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-SVM的推导-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/10/机器学习-SVM的推导-1/" class="article-date">
  <time datetime="2018-08-10T14:36:53.000Z" itemprop="datePublished">2018-08-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/10/机器学习-SVM的推导-1/">[机器学习]SVM的推导(1)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="硬间隔的SVM推导"><a href="#硬间隔的SVM推导" class="headerlink" title="硬间隔的SVM推导"></a>硬间隔的SVM推导</h1><p>SVM是机器学习中的一种经典方法，除了硬间隔SVM之外，还包括软间隔SVM，核技巧等SVM的变种，本文主要介绍<strong>硬间隔SVM</strong>的推导。</p>
<p>假设两类样本点是可以被准确分开的，那么则可以使用硬间隔SVM来进行分类，假设分隔的超平面方程为<script type="math/tex">w\cdot x+b=0</script>，则每个样本点<script type="math/tex">x_{i}</script>到该超平面的距离为<script type="math/tex">|w\cdot x_{i}+b|</script>，如果设定与超平面之间的距离为正的点为正分类，即<script type="math/tex">y_{i}=+1</script>，相反负距离的点为负分类，即<script type="math/tex">y_{i}=-1</script>，那么可以将样本点到分离超平面的距离表示为<script type="math/tex">\hat{\gamma}_{i}=y_{i}(w\cdot x_{i}+b)</script>，这称为样本点到分离超平面之间的<strong>函数距离</strong>。</p>
<p>令<script type="math/tex">\hat{\gamma}=min(\hat{\gamma}_{i})</script>，即为最小函数距离。需要注意到，函数距离<script type="math/tex">\hat{\gamma}_{i}=y_{i}(w\cdot x_{i}+b)</script>在<script type="math/tex">w</script>和<script type="math/tex">b</script>同时增大某个比例倍数时，函数间隔会增大但是超平面不会发生改变，此时便需要将超平面的<script type="math/tex">w</script>进行约束，比如令<script type="math/tex">||w||=1</script>，我们可以重新定义距离为<script type="math/tex">\gamma_{i}=y_{i}(\frac{w}{||w||}\cdot x_{i}+\frac{b}{||w||})</script>，称之为<strong>几何距离</strong>，令<script type="math/tex">\gamma=min(\gamma_{i})</script>，即可以得到<script type="math/tex">\gamma=\frac{\hat\gamma}{||w||}</script>。</p>
<p>那么最大化分隔距离的优化问题即可表示如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
&max_{w,b}\quad \gamma \\
&s.t.\quad y_{i}(\frac{w}{||w||}\cdot x_{i}+\frac{b}{||w||})\ge\gamma，i=1,2...n
\end{align*}</script><p>即</p>
<script type="math/tex; mode=display">
\begin{align*}
&max_{w,b}\quad \frac{\hat\gamma}{||w||} \\
&s.t.\quad y_{i}(w\cdot x_{i}+b)\ge\hat \gamma，i=1,2...n
\end{align*}</script><p>注意上式中，函数间隔<script type="math/tex">\hat\gamma</script>的取值并不会影响最优化问题的解，不妨假设<script type="math/tex">\hat\gamma=1</script>，并且注意到最大化<script type="math/tex">\frac{1}{||w||}</script>与最小化<script type="math/tex">\frac{1}{2}||w||^{2}</script>等价，那么上述问题即可以等价为：</p>
<script type="math/tex; mode=display">
\begin{align*}
&min_{w,b}\quad \frac{1}{2}||w||^{2}\\
&s.t.\quad y_{i}(w\cdot x_{i}+b)-1\ge0
\end{align*}</script><p>上述问题即为一个不等式约束的最优化问题，可以利用拉格朗日乘子法与KKT条件来求解，令<script type="math/tex">\alpha=[\alpha_{1},\alpha_{2},\alpha_{3},...,\alpha_{n}]^{T}</script>，首先构造拉格朗日函数为：<script type="math/tex">L(w,b,\alpha)=\frac{1}{2}||w||^{2}-\sum_{i}\alpha_{i}y_{i}(w\cdot x_{i}+b)+\sum_{i}\alpha_{i}</script></p>
<p>假设<script type="math/tex">W^{*},b^{*},\alpha^{*}</script>是优化问题的最优解，那么根据KKT条件，<script type="math/tex">W^{*},b^{*},\alpha^{*}</script>一定满足以下方程：</p>
<script type="math/tex; mode=display">
\begin{align}
&\nabla_{w}L(w^{*},b^{*},\alpha^{*})=w^{*}-\sum_{i=1}^{N}\alpha^{*}_{i}y_{i}x_{i}=0\tag{1}\\
&\nabla_{b}L(w^{*},b^{*},\alpha^{*})=-\sum_{i=1}^{N}\alpha_{i}^{*}y_{i}=0\tag{2}\\
&\alpha_{i}^{*}(y_{i}(w^{*}\cdot x_{i}+b^{*})-1)=0\tag{3}\\
&y_{i}(w^{*}\cdot x_{i}+b^{*})-1\ge 0\tag{4}\\
&\alpha_{i}^{*}\ge0\tag{5}
\end{align}</script><p>KKT条件主要包括几个方面的内容：<br>1.拉格朗日函数对于原始优化变量的梯度为0，如（1）和（2）<br>2.拉格朗日乘子和不等式约束的左式（化为标准形式）的乘积全为0，如（3）<br>3.原问题的约束条件，如（4）<br>4.拉格朗日乘子非负，如（5）</p>
<p>由（1）和（2）可以得到：</p>
<script type="math/tex; mode=display">
w^{*}=\sum_{i}^{N}\alpha_{i}^{*}y_{i}x_{i}\\
\sum_{i}^{N}\alpha_{i}^{*}y_{i}=0</script><p>根据拉格朗日对偶性，原问题可以化为：</p>
<script type="math/tex; mode=display">
min_{w,b}\ max_{\alpha}\ \frac{1}{2}||w||^{2}-\sum_{i}\alpha_{i}y_{i}(w\cdot x_{i}+b)+\sum_{i}\alpha_{i},\alpha_{i}\ge 0</script><p>即</p>
<script type="math/tex; mode=display">
max_{\alpha}\ min_{w,b}\ \frac{1}{2}||w||^{2}-\sum_{i}\alpha_{i}y_{i}(w\cdot x_{i}+b)+\sum_{i}\alpha_{i},\alpha_{i}\ge 0</script><p>其中<script type="math/tex">min_{w,b}\ \frac{1}{2}||w||^{2}-\sum_{i}\alpha_{i}y_{i}(w\cdot x_{i}+b)+\sum_{i}\alpha_{i}</script>问题的最优解由KKT条件可以得到为<script type="math/tex">w^{*}=\sum_{i}^{N}\alpha_{i}^{*}y_{i}x_{i}</script>，并且有<script type="math/tex">\sum_{i}^{N}\alpha_{i}^{*}y_{i}=0</script>，代入上式即可将原问题化为：</p>
<script type="math/tex; mode=display">
\begin{align*}
max_{\alpha}\quad&-\frac{1}{2}\sum_{i}\sum_{j}\alpha_{i}\alpha_{j}y_{i}y_{j}(x_{i}\cdot x_{j})+\sum_{i}\alpha_{i}\\
s.t.\quad&\alpha_{i}\ge 0
\end{align*}</script><p>在求解了<script type="math/tex">\alpha^{*}</script>之后，即可根据<script type="math/tex">w^{*}=\sum_{i}^{N}\alpha_{i}^{*}y_{i}x_{i}</script>求得<script type="math/tex">w^{*}</script>，由于分离超平面的参数是<script type="math/tex">w^{*},b^{*}</script>决定的，而分离超平面由<script type="math/tex">\alpha_{i}\neq0</script>的<script type="math/tex">\alpha_{i},x_{i},y_{i}</script>决定的，因此再选取任意<script type="math/tex">j</script>使得<script type="math/tex">\alpha_{j}\neq0</script>，得到<script type="math/tex">b^{*}=y_{j}-w^{*}\cdot x_{j}</script>，这样便可以得到分离超平面<script type="math/tex">w^{*}\cdot x+b^{*}=0</script>。</p>
<p>对于上面的求解<script type="math/tex">\alpha^{*}</script>的优化问题，我们在下文将会介绍SMO算法来求解<br>To be continuue…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/10/机器学习-SVM的推导-1/" data-id="cjlote7m30011x4ezb3a4mfhm" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-最优化-求解线性方程组-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/26/最优化-求解线性方程组-3/" class="article-date">
  <time datetime="2018-07-26T14:24:16.000Z" itemprop="datePublished">2018-07-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/26/最优化-求解线性方程组-3/">[最优化]求解线性方程组(3)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="求解线性方程组-3"><a href="#求解线性方程组-3" class="headerlink" title="求解线性方程组(3)"></a>求解线性方程组(3)</h1><h2 id="矩阵的伪逆"><a href="#矩阵的伪逆" class="headerlink" title="矩阵的伪逆"></a>矩阵的伪逆</h2><p>这里所介绍的伪逆是<strong>Moore-Penrose逆矩阵</strong>，其定义为：给定矩阵<script type="math/tex">A\in R^{m*n}</script>，如果矩阵<script type="math/tex">A^{\dagger}\in R^{n*m}</script>满足<script type="math/tex">AA^{\dagger}A=A</script>，且存在两个矩阵<script type="math/tex">U\in R^{n*n},V\in R^{m*m}</script>使得</p>
<script type="math/tex; mode=display">
A^{\dagger}=UA^{T},A^{\dagger}=A^{T}V</script><p>那么则称<script type="math/tex">A^{\dagger}</script>是矩阵<script type="math/tex">A</script>的<strong>伪逆</strong>，可以通过证明得到，矩阵的伪逆是<strong>唯一</strong>的。</p>
<p>对于矩阵<script type="math/tex">A\in R^{m*n},m\ge n</script>且<script type="math/tex">rank(A)=n</script>，可以根据以上定义验证得到<script type="math/tex">A</script>的伪逆为</p>
<script type="math/tex; mode=display">
A^{\dagger}=(A^{T}A)^{-1}A^{T}</script><p>对于矩阵<script type="math/tex">A\in R^{m*n},m\le n</script>且<script type="math/tex">rank(A)=m</script>，同样根据以上定义验证得到<script type="math/tex">A</script>的伪逆为</p>
<script type="math/tex; mode=display">
A^{\dagger}=A^{T}(AA^{T})^{-1}</script><p>以上两种情况是当矩阵为<strong>列满秩</strong>或者<strong>行满秩</strong>情况下的伪逆，而对于一般矩阵<script type="math/tex">A\in R^{m*n},rank(A)=r,r\le min(m,n)</script>，我们可以采用<strong>满秩分解</strong>的方法来求得其伪逆。</p>
<p>对于任意矩阵<script type="math/tex">A\in R^{m*n},rank(A)=r,r\le min(m,n)</script>，都可以将其分解为一个行满秩矩阵和列满秩矩阵的乘积：<br>即<script type="math/tex">A=BC,B\in R^{m*r},c\in R^{r*n},rank(A)=rank(B)=rank(C)=r</script></p>
<p>可以通过证明得到：</p>
<p><script type="math/tex">A^{\dagger}=C^{\dagger}B^{\dagger}</script>，而其中<script type="math/tex">B^{\dagger}=(B^{T}B)^{-1}B^{T},C^{\dagger}=C^{T}(CC^{T})^{-1}</script>，即为一般矩阵的伪逆求法。</p>
<h2 id="一般情况下线性方程组的解法"><a href="#一般情况下线性方程组的解法" class="headerlink" title="一般情况下线性方程组的解法"></a>一般情况下线性方程组的解法</h2><p>某线性方程组为<script type="math/tex">Ax=b,A\in R^{m*n},rank(A)=r</script>，向量<script type="math/tex">x^{*}=A^{\dagger}b</script>可在空间<script type="math/tex">R^{n}</script>中最小化<script type="math/tex">||Ax-b||^{2}</script>;而且在<script type="math/tex">R^{n}</script>中所有能够最小化<script type="math/tex">||Ax-b||^{2}</script>的向量中，向量<script type="math/tex">x^{*}=A^{\dagger}b</script>的范数最小，并且是唯一的。</p>
<p>当<script type="math/tex">r=m</script>时，<script type="math/tex">A</script>是行满秩矩阵，此时<script type="math/tex">x^{*}=A^{\dagger}b=A^{T}(AA^{T})^{-1}b</script>，即为方程组<script type="math/tex">Ax=b</script>的<strong>最小范数解</strong>。</p>
<p>当<script type="math/tex">r=n</script>时，<script type="math/tex">A</script>是列满秩矩阵，此时<script type="math/tex">x^{*}=A^{\dagger}b=(A^{T}A)^{-1}A^{T}b</script>，即为方程组<script type="math/tex">Ax=b</script>的<strong>最小二乘解</strong>。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/26/最优化-求解线性方程组-3/" data-id="cjlote7l4000ex4ezuqz9stq5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/optimization/">optimization</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
<div class="widget-wrap">
  <h3 class="widget-title">ABOUT ME</h3>
  <ul class="widget about-me">
    
    <li><img class="author" title="About me" src="/images/cute.jpg" /></li>
    
    
    <li>Name：Tang Lang</li>
    
    <li>School：Xiamen University</li>
    
    <li>Email：langtang1996@gmail.com</li>
    
    <li>QQ：1660039482</li>
    
  </ul>
</div>


  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cpp/">Cpp</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/optimization/">optimization</a><span class="tag-list-count">9</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Cpp/" style="font-size: 15px;">Cpp</a> <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a> <a href="/tags/optimization/" style="font-size: 20px;">optimization</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/08/31/最优化-凸集的定义与常见凸集/">[最优化]凸集的定义与常见凸集</a>
          </li>
        
          <li>
            <a href="/2018/08/24/机器学习-SVM的推导-3/">[机器学习]SVM的推导(3)</a>
          </li>
        
          <li>
            <a href="/2018/08/18/机器学习-SVM的推导-2/">[机器学习]SVM的推导(2)</a>
          </li>
        
          <li>
            <a href="/2018/08/10/机器学习-SVM的推导-1/">[机器学习]SVM的推导(1)</a>
          </li>
        
          <li>
            <a href="/2018/07/26/最优化-求解线性方程组-3/">[最优化]求解线性方程组(3)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Tang Lang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>
</html>