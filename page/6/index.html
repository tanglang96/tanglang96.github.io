<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Math &amp; Code</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="the best or nothing">
<meta name="keywords" content="Algorithm">
<meta property="og:type" content="website">
<meta property="og:title" content="Math &amp; Code">
<meta property="og:url" content="http://yoursite.com/page/6/index.html">
<meta property="og:site_name" content="Math &amp; Code">
<meta property="og:description" content="the best or nothing">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Math &amp; Code">
<meta name="twitter:description" content="the best or nothing">
  
    <link rel="alternate" href="/atom.xml" title="Math &amp; Code" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Math &amp; Code</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">---By Frank,the best or nothing</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Cpp-Cpp中的关联容器" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/01/Cpp-Cpp中的关联容器/" class="article-date">
  <time datetime="2018-06-01T07:54:28.000Z" itemprop="datePublished">2018-06-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/01/Cpp-Cpp中的关联容器/">[Cpp]Cpp中的关联容器</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="关联容器"><a href="#关联容器" class="headerlink" title="关联容器"></a>关联容器</h1><p>关联容器支持高效的关键字查找和访问，两个主要的关联容器是set和map。map中的元素是一些键值对(key-value)，关键字起着索引的作用，值则表示与索引相关联的数据，set中的元素只包含一个关键字。set支持高效的关键字查找操作，底层应该是用的哈希表来实现的。</p>
<p>C++标准库提供了8个关联容器，这8个容器的不同体现在三个维度上：</p>
<ol>
<li>set或者map</li>
<li>有序或者无序—-有无unordered前缀</li>
<li>允许或禁止重复关键字—-有无multi前缀</li>
</ol>
<p>本文重点介绍set和map，关于其他容器的相关内容可以查看C++的API</p>
<h2 id="set与map的使用"><a href="#set与map的使用" class="headerlink" title="set与map的使用"></a>set与map的使用</h2><p>使用map：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//统计每个单词在输入中出现的次数</span></span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">size_t</span>&gt; word_count;	<span class="comment">//新建map</span></span><br><span class="line"><span class="built_in">string</span> word;</span><br><span class="line"><span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;word)</span><br><span class="line">	++word_count[word];    <span class="comment">//将该单词所对应的次数加1</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">const</span> <span class="keyword">auto</span> &amp;w:word_count)</span><br><span class="line">	<span class="built_in">cout</span>&lt;&lt;w.first&lt;&lt;<span class="string">" occurs "</span>&lt;&lt;w.second&lt;&lt;((w.second&gt;<span class="number">1</span>)?<span class="string">" times"</span>:<span class="string">" time"</span>)&lt;&lt;<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure></p>
<p>需要注意，对于map的下标操作如果使用word_count[word]，在未找到word关键字的时候会添加一个关键字为word的元素，对其值进行初始化。如果使用word_count.at(word)，在未找到word关键字的时候会抛出一个out_of_range异常。</p>
<p>使用set：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//统计输入中每个单词出现的次数</span></span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">size_t</span>&gt; word_count;</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt; exclude=&#123;<span class="string">"The"</span>,<span class="string">"But"</span>,<span class="string">"And"</span>,<span class="string">"Or"</span>,<span class="string">"An"</span>&#125;;</span><br><span class="line"><span class="built_in">string</span> word;</span><br><span class="line"><span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;word)</span><br><span class="line">	<span class="keyword">if</span>(exclude.find(word)==exclude.end())   <span class="comment">//当在set中未find时，返回尾迭代器</span></span><br><span class="line">	++word_count[word];</span><br></pre></td></tr></table></figure></p>
<h2 id="pair类和关联容器中额外的类型别名"><a href="#pair类和关联容器中额外的类型别名" class="headerlink" title="pair类和关联容器中额外的类型别名"></a>pair类和关联容器中额外的类型别名</h2><p>pair类定义在头文件utility中，一个pair保存两个数据成员。类似于容器，pair是一个用来生成特定类型的模板。当创建一个pair的时候，我们必须提供两个类型名。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pair&lt;<span class="built_in">string</span>,<span class="keyword">size_t</span>&gt; word_count;	<span class="comment">//保存string和size_t</span></span><br></pre></td></tr></table></figure>
<p>与其他的标准库类型不同，pair的数据成员是public的，两个成员分别命名为first和second，map中保存的元素就是pair类型的。</p>
<p>关联容器还定义了其他的类型，这些类型表示容器关键字和值的类型：</p>
<ul>
<li>key_type   容器的关键字类型</li>
<li>mapped_type   每个关键字关联的类型，只适用于map</li>
<li>value_type   对于set，与key_type相同，对于map，为pair<const key_type,mapped_type=""><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;::value_type v1;	<span class="comment">//string</span></span><br><span class="line"><span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;::key_type v2;  <span class="comment">//string</span></span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt;::value_type v3;	<span class="comment">//pair&lt;const string,int&gt;</span></span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt;::key_type v4;	<span class="comment">//string</span></span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">int</span>&gt;::mapped_type v5;<span class="comment">//int</span></span><br></pre></td></tr></table></figure>
</const></li>
</ul>
<h2 id="关联容器的迭代器"><a href="#关联容器的迭代器" class="headerlink" title="关联容器的迭代器"></a>关联容器的迭代器</h2><p>当解引用一个关联容器的迭代器时，会得到一个类型为容器的value_type的值的引用。对map而言，value_type是一个pair类型，其first成员保存const的关键字，second成员保存值：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获得指向word_count中一个元素的迭代器</span></span><br><span class="line"><span class="keyword">auto</span> map_it=word_count.begin();</span><br><span class="line"><span class="comment">//*map_it是指向一个pair&lt;const string,size_t&gt;对象的引用</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;map_it-&gt;first;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;<span class="string">" "</span>&lt;&lt;map_it-&gt;second;</span><br><span class="line">map_it-&gt;first=<span class="string">"new key"</span>;  <span class="comment">//错误，关键字是const的</span></span><br><span class="line">++map_it-&gt;second;   <span class="comment">//值的元素是可以改变的</span></span><br></pre></td></tr></table></figure></p>
<p>一个set中的关键字也是const的。可以用一个set来读取元素的值，但是不能修改：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt; iset=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&#125;;</span><br><span class="line"><span class="built_in">set</span>&lt;<span class="keyword">int</span>&gt;::iterator set_it=iset.begin();</span><br><span class="line"><span class="keyword">if</span>(set_it!=iset.end())&#123;</span><br><span class="line">	*set_it=<span class="number">42</span>;   <span class="comment">//错误，const的关键字不能修改</span></span><br><span class="line">	<span class="built_in">cout</span>&lt;&lt;*set_it&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/06/01/Cpp-Cpp中的关联容器/" data-id="cjov8u72700000oaw4w7eiblg" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cpp/">Cpp</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-神经网络反向传播的推导" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/06/01/机器学习-神经网络反向传播的推导/" class="article-date">
  <time datetime="2018-06-01T05:20:32.000Z" itemprop="datePublished">2018-06-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/06/01/机器学习-神经网络反向传播的推导/">[机器学习]神经网络反向传播的推导</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="神经网络反向传播的推导"><a href="#神经网络反向传播的推导" class="headerlink" title="神经网络反向传播的推导"></a>神经网络反向传播的推导</h1><p>对于神经网络的训练过程而言，其反向传播算法是训练过程的核心，神经网络根据预测值$\hat{y}$与实际值$y$的偏差从后向前来计算损失函数对于各个参数的梯度，从而利用梯度下降的方法来优化训练神经网络的各个参数。</p>
<p>神经网络的计算流程图如下：<br><img src="https://img-blog.csdn.net/2018060112352186?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>从该流程图可以看到，如果我们要计算神经网络的参数$W^{[1]},b^{[1]},W^{[2]},b^{[2]}$，首先需要计算$\frac{\partial L}{\partial a^{[2]}}$和$\frac{\partial a^{[2]}}{\partial z^{[2]}}$，然后根据链式法则得到$\frac{\partial L}{\partial z^{[2]}}=\frac{\partial L}{\partial a^{[2]}}\frac{\partial a^{[2]}}{\partial z^{[2]}}$。</p>
<p>之后再计算$\frac{\partial z^{[2]}}{\partial W^{[2]}}$和$\frac{\partial z^{[2]}}{\partial b^{[2]}}$，同样根据链式法则可以得到$\frac{\partial L}{\partial W^{[2]}}=\frac{\partial L}{\partial z^{[2]}}\frac{\partial z^{[2]}}{\partial W^{[2]}}$以及得到$\frac{\partial L}{\partial b^{[2]}}=\frac{\partial L}{\partial z^{[2]}}\frac{\partial z^{[2]}}{\partial b^{[2]}}$。这样便得到了$dW^{[2]}$和$db^{[2]}$。</p>
<p>另外对于$dW^{[1]}$和$db^{[1]}$的计算，需要先计算$\frac{\partial z^{[1]}}{\partial W^{[1]}}$，$\frac{\partial a^{[1]}}{\partial z^{[1]}}$和$\frac{\partial z^{[2]}}{\partial a^{[1]}}$，同样根据链式法则可以得到$\frac{\partial L}{\partial W^{[1]}}=\frac{\partial L}{\partial z^{[2]}}\frac{\partial z^{[2]}}{\partial a^{[1]}}\frac{\partial a^{[1]}}{\partial z^{[1]}}\frac{\partial z^{[1]}}{\partial W^{[1]}}$，以及$\frac{\partial L}{\partial b^{[1]}}=\frac{\partial L}{\partial z^{[2]}}\frac{\partial z^{[2]}}{\partial a^{[1]}}\frac{\partial a^{[1]}}{\partial z^{[1]}}\frac{\partial z^{[1]}}{\partial b^{[1]}}$。这样也得到了$dW^{[1]}$和$db^{[1]}$。</p>
<p>在使用随机梯度下降(SGD)优化算法以及交叉熵(Cross Entropy)损失函数的时候，我们令$a^{[2]}=\hat{y}$，即损失函数：</p>
<script type="math/tex; mode=display">L(\hat{y},y)=-(ylog\hat{y}+(1-y)log(1-\hat{y}))</script><p>使用sigmoid激活函数，即</p>
<script type="math/tex; mode=display">a^{[1]}=\sigma(z^{[1]})=\frac{1}{1+e^{-z^{[1]}}}\\a^{[2]}=\sigma(z^{[2]})=\frac{1}{1+e^{-z^{[2]}}}</script><p>将该激活函数和损失函数代入上面的计算过程，可以得到：</p>
<script type="math/tex; mode=display">
dz^{[2]}=a^{[2]}-y\\
dW^{[2]}=dz^{[2]}a^{[1]T}\\
db^{[2]}=dz^{[2]}\\
dz^{[1]}=W^{[2]T}dz^{[2]}*\sigma^{'}(z^{[1]})\\
dW^{[1]}=dz^{[1]}x^{T}\\
db^{[1]}=dz^{[1]}</script><p>在进行随机梯度下降的过程中，随机选取样本中的一个错误分类点，根据该点计算当前的$dW^{[1]},db^{[1]},dW^{[2]},db^{[2]}$，然后利用以下公式来更新$W^{[1]},b^{[1]},W^{[2]},b^{[2]}$：</p>
<script type="math/tex; mode=display">
W^{[2]}:=W^{[2]}-\alpha *dW^{[2]}\\
b^{[2]}:=b^{[2]}-\alpha *db^{[2]}\\
W^{[1]}:=W^{[1]}-\alpha *dW^{[1]}\\
b^{[1]}:=b^{[1]}-\alpha *db^{[1]}</script><p>直到收敛为止。</p>
<p>对于神经网络的训练，还有批量梯度下降(Batch Gradient Descent)和小批量梯度下降(Mini-Batch Gradient Descent)，带动量的随机梯度下降(Momentum)，RMSProp，Adam等方法，后面再做详解。</p>
<p>To be continue…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/06/01/机器学习-神经网络反向传播的推导/" data-id="cjov8u73p00230oawjmcx3o1c" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Cpp-Cpp中的顺序容器" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/25/Cpp-Cpp中的顺序容器/" class="article-date">
  <time datetime="2018-05-25T14:48:13.000Z" itemprop="datePublished">2018-05-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/25/Cpp-Cpp中的顺序容器/">[Cpp]Cpp中的顺序容器</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="C-中的顺序容器"><a href="#C-中的顺序容器" class="headerlink" title="C++中的顺序容器"></a>C++中的顺序容器</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>一个容器就是一些特定类型对象的集合。顺序容器提供了控制元素存储和访问顺序的能力。<br>顺序容器类型</p>
<ul>
<li><strong>vector</strong>：可变大小数组，支持快速随机访问</li>
<li><strong>deque</strong>：双端队列，支持快速随机访问</li>
<li><strong>list</strong>：双向链表，只支持双向顺序访问</li>
<li><strong>forward_list</strong>：单向链表，只支持单向顺序访问</li>
<li><strong>array</strong>：固定大小数组</li>
<li><strong>string</strong>：与vector类似，仅用于保存和字符</li>
</ul>
<p>选取顺序容器的一些准则：</p>
<ol>
<li>与内置数组相比，array是一种更安全，更容易使用的数组类型，现代C++程序应该使用标准库容器，而不是更原始的数据结构比如内置数组</li>
<li>除非有很好的理由选择其他容器，否则使用vector</li>
<li>其余的选择准则可以根据数组/链表/队列等数据结构的性质来判定</li>
</ol>
<h2 id="容器库与顺序容器操作"><a href="#容器库与顺序容器操作" class="headerlink" title="容器库与顺序容器操作"></a>容器库与顺序容器操作</h2><p>关于顺序容器的大部分操作都可以在C++的API中查到，本文不再赘述，在这里仅谈几个注意事项：<br>关于<strong>迭代器</strong>：</p>
<ol>
<li>迭代器的c.end()指向的是最后一个元素之后的位置，c.begin()与c.end()这样一组迭代器的范围是左闭区间，右开区间</li>
<li>单向链表forward_list不支持迭代器的递减操作，根据单向链表的数据结构性质很容易理解</li>
<li>begin和end相等则范围为空，不等则至少包含一个元素</li>
<li>将一个容器创建为另一个容器的拷贝的时候，需要两个容器的类型和其元素类型都一致，在传入迭代器范围进行拷贝的时候不需要元素类型一致，只要能转换成对应元素就可以。</li>
<li>除了string之外，指向容器的迭代器、引用和指针在swap之后都不会失效，仍指向swap之前的那些元素，但是对于string，它们都会失效。</li>
</ol>
<p>关于<strong>swap</strong>：未完待续<br>关于<strong>forward_list</strong>：未完待续<br>关于<strong>string</strong>：未完待续</p>
<h2 id="关于vector的扩容"><a href="#关于vector的扩容" class="headerlink" title="关于vector的扩容"></a>关于vector的扩容</h2><p>vector对象是连续存储的，标准库实现者采取了可以减少容器空间重新分配次数的策略，当不得不获取新的内存空间时，vector和string的实现通常会分配比新的空间需求更大的内存空间，在使用该策略后，其扩张速度通常比list和deque快得多。</p>
<p>需要注意capacity和size的区别：容器的size是指它已经保存的元素的数目；而capacity则是在不分配新的内存空间的前提下其最多能保存的元素个数。</p>
<h2 id="容器适配器"><a href="#容器适配器" class="headerlink" title="容器适配器"></a>容器适配器</h2><p>除了顺序容器外，标准库还定义了三个顺序容器适配器：stack，queue和priority_queue。适配器(adapter)是标准库中的一个通用概念。容器，函数和迭代器都有适配器。本质上，一个适配器是一种机制，能使某种事物的行为看起来像另外一种事物一样。一个容器适配器接受一种已有的容器类型，使其行为看起来像一种不同的类型。</p>
<p>例如，stack适配器接受一种已有的容器类型，使其行为看起来像stack一样。可以理解为利用某种顺序容器实现的stack类，并且抽象出来了pop()，push()等操作。</p>
<p>priority_queue和queue的区别在于priority_queue可以为队列中的元素建立优先级。至于stack，queue，priority_queue三者的具体操作细节，可以查看C++的相关API。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/05/25/Cpp-Cpp中的顺序容器/" data-id="cjov8u72h00040oawl8eoljk2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cpp/">Cpp</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-机器学习-决策树和随机森林算法简介" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/24/机器学习-决策树和随机森林算法简介/" class="article-date">
  <time datetime="2018-05-24T13:22:21.000Z" itemprop="datePublished">2018-05-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/24/机器学习-决策树和随机森林算法简介/">[机器学习]决策树和随机森林算法简介</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="决策树和随机森林算法简介"><a href="#决策树和随机森林算法简介" class="headerlink" title="决策树和随机森林算法简介"></a>决策树和随机森林算法简介</h1><h2 id="1-决策树"><a href="#1-决策树" class="headerlink" title="1-决策树"></a>1-决策树</h2><h2 id="1-1-决策树模型的结构"><a href="#1-1-决策树模型的结构" class="headerlink" title="1.1-决策树模型的结构"></a>1.1-决策树模型的结构</h2><p>决策树（decision tree）是一种分类与回归方法，本文主要讨论用于分类的决策树，决策树的结构呈树形结构，在分类问题中，其代表基于特征对数据进行分类的过程，通常可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。其主要优点是模型可读性好并且分类速度快。训练的时候，利用训练数据根据损失函数最小化的原则建立决策树模型。预测时对于新的数据，利用决策树进行分类。决策树的学习通常包括三个步骤：特征选择，生成决策树，对决策树进行剪枝。这些决策树的思想主要来自Quinlan在1986年提出的ID3算法和1993年提出的C4.5算法，以及Breiman等人在1984年提出的CART算法。</p>
<p>用于分类的决策树是一种对数据进行分类的树形结构。决策树主要由节点（node）和有向边（directed edge）组成。节点有两种类型：内部节点（internal node）以及叶节点（leaf node）。内部节点表示一个特征或者属性，叶节点表示一个类。其结构如图所示：<br><img src="https://img-blog.csdn.net/20180524210204247?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="决策树算法的结构"></p>
<h2 id="1-2-特征选择"><a href="#1-2-特征选择" class="headerlink" title="1.2-特征选择"></a>1.2-特征选择</h2><p>特征选择在于选取对训练数据具有分类能力的特征，这样可以提高决策树的学习效率，如果利用一个特征进行分类的结果与随机分类的结果没有太大差别，则称这个特征是没有分类能力的。通常扔掉这样的特征对于决策树的学习精度影响不大，通常特征选取的准则是信息增益或者信息增益比。</p>
<p>在信息论中，熵（entropy）是表示随机变量不确定性的度量，设X是一个取有限个值得离散随机度量，其概率分布为：</p>
<script type="math/tex; mode=display">
P(X={ {x}_{i} })={ {p}_{i} },i=1,2,...,n</script><p>那么随机变量的熵定义为：</p>
<script type="math/tex; mode=display">
H(X)=-\sum\limits_{i=1}^{n}{ { {p}_{i} }\log { {p}_{i} } }</script><p>熵越大，随机变量的不确定性越大，从定义可以验证</p>
<script type="math/tex; mode=display">
0\le H(p)\le \log n</script><p>当<script type="math/tex">p=0</script>或<script type="math/tex">p=1</script>时<script type="math/tex">H(p)=0</script> ，随机变量完全没有不确定性，当<script type="math/tex">p=0.5</script>时，<script type="math/tex">H(p)=1</script>，熵取值最大，随机变量的不确定性最大。</p>
<p>条件熵<script type="math/tex">H(Y|X)</script>表示在已知随机变量的条件下随机变量的不确定性。随机变量<script type="math/tex">X</script>给定的条件下随机变量<script type="math/tex">Y</script>的条件熵（conditional entropy）<script type="math/tex">H(Y|X)</script>，定义为 <script type="math/tex">X</script>给定条件下<script type="math/tex">Y</script>的条件概率分布的熵对<script type="math/tex">X</script>的数学期望</p>
<script type="math/tex; mode=display">
H(Y|X)=\sum\limits_{i=1}^{n}{ { {p}_{i} }H(Y|X={ {x}_{i} })}</script><p>这里<script type="math/tex">{ {p}_{i} }=P(X={ {x}_{i} }),i=1,2,...,n</script>，信息增益（information gain）表示得知特征<script type="math/tex">X</script>的信息而使得类<script type="math/tex">Y</script>的不确定性减小的程度。</p>
<p>特征<script type="math/tex">A</script>对训练集<script type="math/tex">D</script>的信息增益<script type="math/tex">g(D,A)</script>定义为集合<script type="math/tex">D</script>的经验熵<script type="math/tex">H(D)</script>与特征<script type="math/tex">A</script>给定条件下<script type="math/tex">D</script>的经验条件熵<script type="math/tex">H(D|A)</script>之差，即</p>
<script type="math/tex; mode=display">
g(D|A)=H(D)-H(D|A)</script><h2 id="1-3-构建决策树的ID3算法"><a href="#1-3-构建决策树的ID3算法" class="headerlink" title="1.3-构建决策树的ID3算法"></a>1.3-构建决策树的ID3算法</h2><p>决策树的算法主要有ID3，C4.5以及CART，ID3算法的核心是在决策树各个节点上应用信息增益准则选取特征，递归构建决策树。<br>下面得到构建决策树的ID3算法：<br>输入：训练数据集D，特征集A，阈值<script type="math/tex">\varepsilon</script>；<br>输出：决策树T.</p>
<p>（1）若D中所有实例属于同一类<script type="math/tex">{ {C}_{k} }</script>，则T为单节点树，并将<script type="math/tex">{ {C}_{k} }</script>作为该节点的类标记，返回T；<br>（2）若A=<script type="math/tex">\varnothing</script>，则T为单节点树，并将D中实例数最大的类<script type="math/tex">{ {C}_{k} }</script>作为该节点的类标记，返回T；<br>（3）否则按照信息增益算法计算A中各特征对D的信息增益，选择信息增益最大的特征<script type="math/tex">{ {A}_{g} }</script>；<br>（4）如果<script type="math/tex">{ {A}_{g} }</script>的信息增益小于阈值<script type="math/tex">\varepsilon</script>，则T为单节点树，并将D中实例数最大的类 作为该节点的类标记，返回T；<br>（5）否则，对<script type="math/tex">{ {A}_{g} }</script>的每一可能值<script type="math/tex">{ {a}_{i} }</script>，依据<script type="math/tex">{ {A}_{g} }={ {a}_{i} }</script>将D分割为若干非空子集<script type="math/tex">{ {D}_{i} }</script>，将<script type="math/tex">{ {D}_{i} }</script>中实例数最大的类作为标记，构建子节点，由节点及其子节点够成树T，返回T；对第i个子节点，以<script type="math/tex">{ {D}_{i} }</script>为训练集，以<script type="math/tex">A-\{ { {A}_{g} }\}</script>为特征集，递归地调用步1-步5，得到子树<script type="math/tex">{ {T}_{i} }</script>，返回<script type="math/tex">{ {T}_{i} }</script>。</p>
<h2 id="2-集成学习"><a href="#2-集成学习" class="headerlink" title="2-集成学习"></a>2-集成学习</h2><p>集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务，有时候也被称为多分类器系统（multi-classfier system）、基于委员会的学习（committee-based learning）等。</p>
<p>下图显示出集成学习的一般结构：先构建一组“个体学习器”（individual learner），再用某种策略将它们结合起来。个体学习器通常由一个现有的学习算法由训练数据产生，例如ID3决策树算法，BP神经网络算法等，此时集成中只包含同种类型的个体学习器，例如“决策树集成”中全是决策树，“神经网络集成”中全是神经网络，这样的集成是“同质”的（homogeneous）。同质集成中的个体学习器也称为“基学习器”（base learner），相应的学习算法称为“基学习算法”（base learning algorithm）。集成也可包含不同类型的个体学习器，例如同时包含决策树和神经网络，这样的集成是“异质”的（heterogenous）。异质集成中的个体学习器由不同的学习算法产生，这是就不再有基学习算法；相应的，个体学习器一般不称为基学习器，常称为“组件学习器”（component learner）或直接称为个体学习器。<br><img src="https://img-blog.csdn.net/20180524211517468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="集成学习器"></p>
<p>集成学习通过将多个学习器进行结合，常常可以获得比单一学习器更为显著优越的泛化性能。这对“弱学习器”（weak learner）尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的，而基学习器有时也被直接成为弱学习器。但是需要注意的是，虽然从理论上来说使用弱学习器集成足以获得好的性能，但在实践中出于种种考虑，例如希望使用较少的个体学习器，或是重用关于常见学习器的一些经验等，人们往往会使用比较强的学习器。</p>
<p>根据个体学习器的生成方式，目前的集成学习方法大致可分为两类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表是Boosting，后者的代表是Bagging和“随机森林”（Random Forest）。</p>
<h2 id="3-随机森林算法"><a href="#3-随机森林算法" class="headerlink" title="3-随机森林算法"></a>3-随机森林算法</h2><p>随机森林（Random Forest，简称RF）[Breiman,2001a]是Bagging的一个扩展变体，RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。具体来说，传统决策树在选择划分属性时是在当前节点的属性集合（假定有d个属性）中选择一个最优属性；而在RF中，对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。这里的参数k控制了随机性的引入程度：若令k=d，则基决策树的构建与传统决策树相同；若令k=1，则是随机选择一个属性用于划分；一般情况下，推荐值<script type="math/tex">k={ {\log }_{2} }d</script>。</p>
<p>随机森林简单，容易实现，计算开销小，令人惊奇的是，它在很多现实任务中表现出了强大的性能，被誉为“<strong>代表集成学习技术水平的方法</strong>”。可以看出，随机森丽对Bagging只做了小改动，但是与Bagging中基学习器的“多样性”仅通过样本扰动而来不同，随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器之间的差异度的增加而进一步提升，决策树的结构如下图：<br><img src="https://img-blog.csdn.net/20180524211653506?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZyYW5ra2tf/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"></p>
<p>对于随机森林的编程，可以使用scikit-learn框架<br><a href="http://scikit-learn.org/stable/user_guide.html#" target="_blank" rel="noopener">http://scikit-learn.org/stable/user_guide.html#</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/05/24/机器学习-决策树和随机森林算法简介/" data-id="cjov8u73l001x0oawml7z9bge" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-最优化-等式约束的优化问题求解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/05/18/最优化-等式约束的优化问题求解/" class="article-date">
  <time datetime="2018-05-18T13:11:35.000Z" itemprop="datePublished">2018-05-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/05/18/最优化-等式约束的优化问题求解/">[最优化]等式约束的优化问题求解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="等式约束的优化问题求解"><a href="#等式约束的优化问题求解" class="headerlink" title="等式约束的优化问题求解"></a>等式约束的优化问题求解</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>本文将讨论下类形状的优化问题</p>
<script type="math/tex; mode=display">
minimize\quad f(x)\\
subject\  to\quad h(x)=0</script><p>其中$x\in R^{n},f:R^{n}\to R,h:R^{n}\to R^{m},h=[h_{1},…,h_{m}]^{T},m\le n$，假定函数$h$连续可微，即$h\in C^{1}$。<br>下面介绍几个基本概念：</p>
<p><strong>正则点</strong>：对于满足约束 <script type="math/tex">h_{1}(x^{*})=0,...,h_{m}(x^{*})=0</script> 的点<script type="math/tex">x^{**}</script>，如果梯度向量 <script type="math/tex">\nabla h_{1}(x^{*}),...,\nabla h_{m}(x^{*})</script> 是线性无关的，则称<script type="math/tex">x^{*}</script>是该约束的一个正则点。</p>
<p><strong>切线空间</strong>：曲面<script type="math/tex">S={x\in R^{n}:h(x)=0}</script>中点<script type="math/tex">x^{*}</script>处的切线空间为集合<script type="math/tex">T(x^{*})=\{ y:Dh(x^{*})y=0\}</script>。可以看出切线空间<script type="math/tex">T(x^{*})</script>是矩阵<script type="math/tex">Dh(x^{*})</script>的零空间，即<script type="math/tex">T(x^{*})=N(Dh(x^{*}))</script>。</p>
<p><strong>法线空间</strong>：曲面<script type="math/tex">S={x\in R^{n}:h(x)=0}</script>中点<script type="math/tex">x^{*}</script>处的法线空间为集合<script type="math/tex">N(x^{*})=\{ x\in R^{n}:x=Dh(x^{*})^{T}z,z\in R^{m}\}</script>。可以看出法线空间<script type="math/tex">N(x^{*})</script>是矩阵<script type="math/tex">Dh(x^{*})</script>的零空间，即<script type="math/tex">N(x^{*})=R(Dh(x^{*})^{T})</script>。</p>
<h2 id="拉格朗日条件"><a href="#拉格朗日条件" class="headerlink" title="拉格朗日条件"></a>拉格朗日条件</h2><p>首先考虑只包含两个决策变量和一个等式约束的优化问题。令<script type="math/tex">h:R^{2}\to R</script>为约束函数，可知函数定义域中<script type="math/tex">x</script>处的梯度<script type="math/tex">\nabla h(x)</script>与通过该点的<script type="math/tex">h(x)</script>水平集正交，选择点<script type="math/tex">x^{*}=[x^{*}_{1},x^{*}_{1}]^{T}</script>使得<script type="math/tex">h(x^{*})=0</script>，且<script type="math/tex">\nabla h(x^{*})\neq 0</script>，经过点<script type="math/tex">x^{*}</script>的水平集为集合<script type="math/tex">\{ x:h(x)=0\}</script>。可利用曲线<script type="math/tex">x(t)</script>在<script type="math/tex">x^{*}</script>领域内进行参数化，<script type="math/tex">x(t)</script>是一个连续可微的向量函数<script type="math/tex">h:R\to R^{2}</script>：</p>
<script type="math/tex; mode=display">
x(t)=[x_{1}(t),x_{1}(t)]^{T},t\in (a,b),x^{*}=x(t^{*}),\dot{x}(t^{*})\neq 0,t^{*}\in (a,b)</script><p>接下来可以证明，<script type="math/tex">\nabla h(x^{*})</script>与<script type="math/tex">\dot{x}(t^{*})</script>正交。由于<script type="math/tex">h</script>在曲线<script type="math/tex">\{x(t):t\in (a,b)\}</script>上是常数0，即对于所有的<script type="math/tex">t\in (a,b)</script>都有</p>
<script type="math/tex; mode=display">
h(x(t))=0</script><p>因此对于任意的<script type="math/tex">t\in(a,b)</script>都有</p>
<script type="math/tex; mode=display">
\frac{d}{dt}h(x(t))=0</script><p>利用链式法则可以得到</p>
<script type="math/tex; mode=display">
\frac{d}{dt}h(x(t))=\nabla h(x(t))^{T}\dot{x}(t)=0</script><p>因此<script type="math/tex">\nabla h(x^{*})</script>和<script type="math/tex">\dot{x}(t^{*})</script>正交<br>当<script type="math/tex">x^{*}</script>是<script type="math/tex">f:R\to R^{2}</script>在满足<script type="math/tex">h(x)=0</script>上的极小点的时候，可以证明，<script type="math/tex">\nabla f(x^{*})</script>与<script type="math/tex">\dot{x}(t^{*})</script>正交，构造关于<script type="math/tex">t</script>的复合函数：</p>
<script type="math/tex; mode=display">
\phi(t)=f(x(t))</script><p>当<script type="math/tex">t=t^{*}</script>的时候取得极小值，根据无约束极值问题的一阶必要条件可知</p>
<script type="math/tex; mode=display">
\frac{d\phi}{dt}(t^{*})=0</script><p>利用链式法则可以得到</p>
<script type="math/tex; mode=display">
\frac{d}{dt}\phi(t^{*})=\nabla f(x(t^{*}))^{T}\dot{x}(t^{*})=\nabla f(x^{*})^{T}\dot{x}(t^{*})=0</script><p>因此，<script type="math/tex">\nabla f(x^{*})</script>和<script type="math/tex">\dot{x}(t^{*})</script>正交，上面已经证明<script type="math/tex">\nabla f(x^{*})</script>与<script type="math/tex">\dot{x}(t^{*})</script>正交，那么向量<script type="math/tex">\nabla f(x^{*})</script>和<script type="math/tex">\nabla h(x^{*})</script>平行，那么可以得到这种情况下的拉格朗日定理：</p>
<p><strong>n=2,m=3时的拉格朗日定理：</strong>设点<script type="math/tex">x^{*}</script>是函数<script type="math/tex">f:R^{2}\to R</script>的一个极小点，约束条件是<script type="math/tex">h(x)=0,h:R^{2}\to R</script>,那么<script type="math/tex">\nabla f(x^{*})</script>和<script type="math/tex">\nabla h(x^{*})</script>平行，即如果<script type="math/tex">\nabla h(x^{*})\neq 0</script>，则存在标量<script type="math/tex">\lambda^{*}</script>，使得</p>
<script type="math/tex; mode=display">
\nabla f(x^{*})+\lambda^{*}\nabla h(x^{*})=0</script><p>其中<script type="math/tex">\lambda^{*}</script>为拉格朗日乘子。<br>将这个定理推广到一般情况下，即<script type="math/tex">f:R^{n}\to R,h:R^{n}\to R^{m},m\le n</script>的时候，可以得到：<br><strong>拉格朗日定理：</strong><script type="math/tex">x^{*}</script>是<script type="math/tex">f:R^{n}\to R</script>的局部极小点（或极大点），约束条件为<script type="math/tex">h(x)=0,h:R^{n}\to R^{m},m\le n</script>。如果<script type="math/tex">x^{*}</script>是正则点，那么存在<script type="math/tex">\lambda^{*}\in R^{m}</script>使得</p>
<script type="math/tex; mode=display">
D f(x^{*})+\lambda^{*T}D h(x^{*})=0</script><h2 id="二阶条件"><a href="#二阶条件" class="headerlink" title="二阶条件"></a>二阶条件</h2><p><strong>二阶必要条件：</strong>设<script type="math/tex">x^{*}</script>是<script type="math/tex">f:R^{n}\to R</script>在约束条件<script type="math/tex">h(x)=0,h:R^{n}\to R^{m},m\le n,f,h\in C^{2}</script>下的局部极小点。如果<script type="math/tex">x^{*}</script>是正则点，那么存在<script type="math/tex">\lambda^{*}\in R^{m}</script>使得</p>
<p> 1.<script type="math/tex">D f(x^{*})+\lambda^{*T}D h(x^{*})=0^{T}</script><br> 2.对于所有的<script type="math/tex">y\in T(x^{*})</script>，都有<script type="math/tex">y^{T}L(x^{*},\lambda^{*})y\ge 0</script></p>
<p><strong>二阶充分条件：</strong>函数<script type="math/tex">f,h\in C^{2}</script>，如果存在点<script type="math/tex">x^{*}\in R^{n}</script>和<script type="math/tex">\lambda^{*}\in R^{m}</script>，使得</p>
<p> 1.<script type="math/tex">D f(x^{*})+\lambda^{*T}D h(x^{*})=0^{T}</script><br> 2.对于所有的<script type="math/tex">y\in T(x^{*})</script>，都有<script type="math/tex">y^{T}L(x^{*},\lambda^{*})y> 0</script></p>
<p>那么<script type="math/tex">x^{*}</script>是<script type="math/tex">f</script>在约束条件<script type="math/tex">h(x)=0</script>下的严格局部极小点</p>
<p>本文介绍了等式约束下的拉格朗日乘子法，后面还将会介绍不等式约束下的拉格朗日乘子法以及KKT条件等，To be continue…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/05/18/最优化-等式约束的优化问题求解/" data-id="cjov8u73e001i0oaw8fo9ajbi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/optimization/">optimization</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/5/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/7/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
<div class="widget-wrap">
  <h3 class="widget-title">ABOUT ME</h3>
  <ul class="widget about-me">
    
    <li><img class="author" title="About me" src="/images/cute.jpg" /></li>
    
    
    <li>Name：Tang Lang</li>
    
    <li>School：Xiamen University</li>
    
    <li>Email：langtang1996@gmail.com</li>
    
    <li>QQ：1660039482</li>
    
  </ul>
</div>


  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cpp/">Cpp</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Matrix/">Matrix</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/optimization/">optimization</a><span class="tag-list-count">9</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Cpp/" style="font-size: 15px;">Cpp</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/algorithm/" style="font-size: 12.5px;">algorithm</a> <a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a> <a href="/tags/optimization/" style="font-size: 17.5px;">optimization</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/22/paper-robot/">[paper]robot</a>
          </li>
        
          <li>
            <a href="/2018/11/17/paper-dqn/">[paper]dqn</a>
          </li>
        
          <li>
            <a href="/2018/11/02/dataset-cityscapes/">dataset-cityscapes</a>
          </li>
        
          <li>
            <a href="/2018/10/30/paper-EDAnet/">[paper]EDAnet</a>
          </li>
        
          <li>
            <a href="/2018/10/22/paper-darts/">[paper]darts</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Tang Lang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>